{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [OpenAI Cookbook 예제](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb) 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv('data\\practice\\.env'))\n",
    "client = OpenAI()\n",
    "from pprint import pprint\n",
    "import json\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row 생략 없이 출력\n",
    "pd.set_option('display.max_rows', None)\n",
    "# col 생략 없이 출력\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레시피 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>날짜</th>\n",
       "      <th>내용</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024년 빅데이터 동아리 투빅스 TOBIGS 나름의 지극히 주관적인 합격 후기 느...</td>\n",
       "      <td>2024-01-08 13:01:32</td>\n",
       "      <td>나름 이번에 21기를 준비하면서 느꼈는데 생각보다 정보가 없어서.. 간단하게 후기를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SESAC 청년취업사관학교도봉 캠퍼스 준비 과정 및 일주일 후기</td>\n",
       "      <td>2024-01-06 15:28:06</td>\n",
       "      <td>여차저차 하면서 시작하게 된 청년취업사관학교 후기를 좀 남겨볼까해요. 아직 일주일 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>나의 뇌는 4개이다 나를 알고 싶을 때 뇌과학을 공부합니다.</td>\n",
       "      <td>2024-01-05 18:08:43</td>\n",
       "      <td>오늘은 최근에 읽게 된 챗북에서 인상깊었던 내용이 있어서 다루어보려 합니다. 한줄로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>간만에 써보는, 인생 전체는 되는대로</td>\n",
       "      <td>2023-12-18 21:18:53</td>\n",
       "      <td>학회 회장 인수인계 자료를 만들다가 문득 간만에 기록을 해본다.  9월, 10월 ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Etri 랩실 하계 인턴 2주 해보고 느낀 것들 정리해보기</td>\n",
       "      <td>2023-07-14 22:56:11</td>\n",
       "      <td>음..이런 느낌의 사회생활은 처음이기에 여러므로 느끼는 바가 많다. 신기하면서도 쉽...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  제목                   날짜  \\\n",
       "0  2024년 빅데이터 동아리 투빅스 TOBIGS 나름의 지극히 주관적인 합격 후기 느...  2024-01-08 13:01:32   \n",
       "1                SESAC 청년취업사관학교도봉 캠퍼스 준비 과정 및 일주일 후기  2024-01-06 15:28:06   \n",
       "2                  나의 뇌는 4개이다 나를 알고 싶을 때 뇌과학을 공부합니다.  2024-01-05 18:08:43   \n",
       "3                               간만에 써보는, 인생 전체는 되는대로  2023-12-18 21:18:53   \n",
       "4                   Etri 랩실 하계 인턴 2주 해보고 느낀 것들 정리해보기  2023-07-14 22:56:11   \n",
       "\n",
       "                                                  내용  \n",
       "0  나름 이번에 21기를 준비하면서 느꼈는데 생각보다 정보가 없어서.. 간단하게 후기를...  \n",
       "1  여차저차 하면서 시작하게 된 청년취업사관학교 후기를 좀 남겨볼까해요. 아직 일주일 ...  \n",
       "2  오늘은 최근에 읽게 된 챗북에서 인상깊었던 내용이 있어서 다루어보려 합니다. 한줄로...  \n",
       "3  학회 회장 인수인계 자료를 만들다가 문득 간만에 기록을 해본다.  9월, 10월 ,...  \n",
       "4  음..이런 느낌의 사회생활은 처음이기에 여러므로 느끼는 바가 많다. 신기하면서도 쉽...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/r2com/Documents/GitHub/sesac-project/data/scripts/notebook/blog_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'제목' : 'title', '날짜' : 'date', '내용' : 'posting'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Learning용 예제 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'content': 'You are a helpful Personal assistant. You are to '\n",
      "                          'extract the personal experience from each of the '\n",
      "                          'posting provided.',\n",
      "               'role': 'system'},\n",
      "              {'content': 'Title: 2024년 빅데이터 동아리 투빅스 TOBIGS 나름의 지극히 주관적인 합격 후기 '\n",
      "                          '느끼는 점 등등..\\n'\n",
      "                          '\\n'\n",
      "                          'Posting date: 2024-01-08 13:01:32\\n'\n",
      "                          '\\n'\n",
      "                          'personal experience: ',\n",
      "               'role': 'user'},\n",
      "              {'content': '나름 이번에 21기를 준비하면서 느꼈는데 생각보다 정보가 없어서.. 간단하게 후기를 남겨보려 '\n",
      "                          '합니다~~  사실 저는 이전에 교내 AI 학회 회장을 마지막 학기에 하면서 이것이 '\n",
      "                          '마지막이겠다 라고 생각했는데... 막상 투빅스 처럼 좋은 커뮤니티와 시스템을 가진 활동도 '\n",
      "                          '참여해보고 싶은 아쉬움이 항상 있었어요. 그래서 불확실한 미래를 가진 졸업유예생 신분이기는 '\n",
      "                          '하지만 나름의 용기와 다짐을 하며 지원을 해보았습니다. 이번이 찐찐막이 될 것 같다는 생각과 '\n",
      "                          '이때 아니면 쉽게 하지 못할 경험이 될 것 같다는 생각에..  아래 홈페이지가 투빅스의 '\n",
      "                          '사이트인데 일단 동아리가 자체 홈페이지를 가지고 운영한다는 부분이 정말 멋지더라구요. 글고 '\n",
      "                          '이전 기수들의 화려한 업적과 경쟁률을 보고 약간 쉽지않겠다는 생각을 많이 했습니다.  일단 '\n",
      "                          '제가 지원했던 21기만 해도 20명 가량을 뽑는 것 같은데 서류 지원자가 거의 190명에 '\n",
      "                          '가까웠어요. 제가 했던 교내 AI학회는 많이도 40명 정도 서류 검토를 했는데.. 서울 연합 '\n",
      "                          '동아리는 확실히 스케일이 다르다는 것을 느꼈어요.ㅎㅎ 다시 본론으로 돌아와서 21기 기준 '\n",
      "                          '서류 전형에 합격하기 위한 대표 질문들은 아래와 같았어요. 질문1 간단한 자기소개와 투빅스에 '\n",
      "                          '지원하신 동기를 적어주세요. 500자 내외 질문2 데이터분석 또는 AI 분야에 어떻게 관심을 '\n",
      "                          '갖게 되었으며, 그와 관련해 어떤 활동노력을 하셨는지 적어주세요. 500자 내외 질문3 협업 '\n",
      "                          '활동프로젝트,팀플 등을 수행하면서 가장 기억에 남는 경험을 적어주세요. 400자 내외 질문4 '\n",
      "                          '투빅스에서 하고 싶은 프로젝트에 대해 자세히 적어주세요. 400자 내외 저의 경우는 하고 '\n",
      "                          '싶은 말이 좀 많아서 ㅎㅎ 글자수를 거의 다 500자 정도로 작성을 했습니다.  제가 '\n",
      "                          '생각하는 글을 쓸 때 약간의 팁이라면 처음보는 사람의 입장에서 저라는 사람이 어떤 사람이며 '\n",
      "                          '어떻게 나라는 사람을 잘 이해시킬지를 고민했어요. 그래서 스토리텔링을 통해 최대한 질문1과 '\n",
      "                          '2는 작성을 했어요.  어떤 글이던 간에 보는이로 하여금 그림이 그려지고 이해가 가능한 글이 '\n",
      "                          '가장 좋은 글이 아닌가 라고 저는 생각을 해요.  물론 너무 장황한 것도 그닥 좋지는 '\n",
      "                          '않지만요.  그리고 질문 3은 제가 작년에 경험한 팀 활동 중에 가장 잘 설명할 수 있다고 '\n",
      "                          '생각하는 소재를 고르고 어떠한 상황이었는지, 아떠한 문제가 있었는지, 그리고 나는 어떻게 '\n",
      "                          '해결을 하려 했는지 그 과정에서 깨달은 내용이 무엇인지 를 최대한 담으려 했어요.  질문 '\n",
      "                          '4는 각자의 니즈에 따라 다채롭게 작성할 수 있을 것 같아요..  이러한 앞선 설명은 단순히 '\n",
      "                          '저라는 사람의 하나의 사례이니 참고정도로만 하시면 좋을 것 같아요.  그렇게 정성스럽게 '\n",
      "                          '작성을 해서..서류를 패스하고 이름은 다른 게시물 뒤적하다 보면 곰방 아실 수 '\n",
      "                          '있겠지만..ㅎㅎ 면접에 관한 사항을 준비하였습니다. 면접은 다대다 방식이고 뽑는 인원의 '\n",
      "                          '3~4배 정도가 면접 심사를 거치기에 사실 붙을지 더 모르겠더라구요.  글고 거의 면접보는 '\n",
      "                          '사람이 70~80명이였는데 제가 본 동아리 면접 중에는 최대규모 여서 좀 긴장을 했던 것 '\n",
      "                          '같아요.  동아리에 들어와서 임원진들을 통해 알게 된 사실은 조가 총 3조로 나누어지는데 '\n",
      "                          '나누어지는 방식은 본인의 관심 분야에 따라 조가 편성된다고 해요. 예를 들면 1조는 '\n",
      "                          '데이터분석, 2조는 자연어, 3조는 이미지 이런 식으로 조가 편성되었다고 해요. 물론 '\n",
      "                          '인원수를 고려하여 정확하게 나누어질 수는 없다는 것 참고해주세요  저의 경우 면접 준비를 '\n",
      "                          '위해 과거 투빅스의 프로젝트 영상 및 자료들을 참고하여 모델에 대해 간단하게 공부를 하고 '\n",
      "                          '자기소개서 내용을 중심으로 리마인드를 하려 했어요. 대충 요런 느낌 왜냐하면 저도 그래도 '\n",
      "                          '몇차례 동아리 운영진으로서 면접을 진행하며 느낀바가 조금 있었기 때문이였던 것 같아요. 저의 '\n",
      "                          '경우 1.지원자가 우리 동아리에 대해 얼만큼 알고 있나  과거 활동들을 찾아보고 어필 2. '\n",
      "                          '지원자가 동아리 활동을 끝까지 마칠 수 있는 사람인가  성실성 및 열정을 보여줄 수 있는 '\n",
      "                          '사례  이 두가지를 중점으로 보았고 실제로 위의 질문에 대해 답변을 잘하는 분들이 인상깊은 '\n",
      "                          '동아리원이기도 했으니까요.  그래서 투빅스의 과거 프로젝트를 찾아보고 저의 성실성을 보여줄 '\n",
      "                          '수 있는 것들도 정리를 해보았는데..  면접을 봐보니 열정은 이미 모든 지원자들이 갖고 '\n",
      "                          '있기에 커리큘럼을 따라올 수 있는 지식을 최소한 갖고 있는지를 중점으로 보시는 것 '\n",
      "                          '같더라구요. 저 역시 4개의 질문을 받았는데  1번 자기소개 2번 서류 지원할 때 작성한 '\n",
      "                          '프로젝트 관련 지식 3번 인공지능 관련 지식 공통 질문 4번 자기소개서 3번 관련 심화 질문 '\n",
      "                          '마지막으로는 마지막 한마디를 하고 면접을 마무리했습니다.  제가 면접자 입장으로 본거는 '\n",
      "                          '오랜만이기도 해서인지.. 약간 긴장이 되기도 하면서 제대로 질문에 답변을 하지 못한 것 '\n",
      "                          '같아서 아쉬웠어요.. 하지만 면접에서 놓치지 않으려한 자신감이랑 본인을 기억 남게하는 '\n",
      "                          '한가지의 소재 혹은 단어 이 두가지를 계속 잡으려고 노력해서인지 몰라도.. 동아리에 합류를 '\n",
      "                          '할 수 있게 되었습니다. 실제로 저는 자기소개 할때 이전 연합동아리에서 나를 대표하는 한가지 '\n",
      "                          '단어를 고민했던 시기에 만든 단어를 토대로 자기소개를 진행했어요. 어짜피 면접관 입장에서 '\n",
      "                          '지원자에 대해 남는 것은 한 단어이더라구요 그리고 남들은 하지 않을 소개 구성을 최대한 '\n",
      "                          '짜려고 하다보니 다행히 기억에 남게되었던 것 같지 않나 싶었어요.  어떤 면접이든 간에 '\n",
      "                          '남들과 다른 뻔하지 않는 구성을 고민해보는 것은 필요한 것 같다고 저 스스로 다시금 느낀 '\n",
      "                          '계기가 된 것 같아요.  아직 처음이라 앞으로 우당탕탕하겠지만.. 해보고 싶었던 활동인 만큼 '\n",
      "                          '열심히 해보며 추후에 최종 동아리 후기도 남기는 것을 목표로 해보겠아요. ',\n",
      "               'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "system_message = \"You are a helpful Personal assistant. You are to extract the personal experience from each of the posting provided.\"\n",
    "\n",
    "def create_user_message(row):\n",
    "    return f\"\"\"Title: {row['title']}\\n\\nPosting date: {row['date']}\\n\\npersonal experience: \"\"\"\n",
    "\n",
    "def prepare_example_conversation(row):\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "    user_message = create_user_message(row)\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": row[\"posting\"]})\n",
    "\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "pprint(prepare_example_conversation(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 측정 목적으로 Training Data와 Test Data 를 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': 'You are a helpful Personal assistant. You are to extract the personal experience from each of the posting provided.'}, {'role': 'user', 'content': 'Title: 5월 19일 매.세.지 더 짧게 정리하기\\n\\nPosting date: 2022-05-19 07:10:08\\n\\npersonal experience: '}, {'role': 'assistant', 'content': ' 와우,,, 오늘 국내장은 거의 파란불 확정이네요... 다우존스는 2020년 이후 최대 하락폭을 기록했다고 합니다. 특히 대형 소매업체 월마트에 이어 타깃이 인플레이션에 따른 비용 압력에 이익이 대폭 줄어든 것으로 나타나면서 물가 상승과 그에 따른 소비 감소 우려에 뉴욕증시의 주요 지수가 폭락한 것으로 보입니다. ㅠㅠ  1. 윤석열 대통령이 20일 방한하는 조 바이든 미국 대통령과 함께 삼성전자 평택 반도체 공장을 찾기로 하였습니다. 미국 대통령이 직접 공장을 찾는 것은 처음이라 더 주목이 되고 있다고 하네요  2. 넥슨과 엔씨소프트는 코로나19 상황에서 3출근2재택근무제를 운영해 오다가 오는 6월부터는 전직원 전면 출근을 지시하였습니다. 네이버와는 반대되는 모습이네요.  3. 한국개발연구원KDI이 우크라이나 전쟁, 공급망 충격 등으로 올해 소비자물가상승률이 4.2에 달할 것으로 전망하였습니다. 스태그플레이션을 단순히 금리인상으로 눌러버릴지 걱정이 되는 부분입니다...ㅠㅠ  4. 윤석열 대통령이 5.18 민주화운동 기념식에 참석해 유족의 손을 맞잡고 임을 위한 행진곡을 힘차게 불렀습니다.  5. 카카오톡에 메시지를 예약해 두었다가 자동으로 전송하는 기능이 도입되었습니다. 이번에 도입한 예약기능을 사용하려면 아이폰이나 아이패드에서 카카오톡 채팅창 우측의 샵을 누르면 나타나는 메시지 예약을 사용하면 된다고 합니다.  6.  고용노동부가 지방의 고용위기 해소를 위해 개별 기업을 대상으로 한 맞춤형 지원 체계 구축에 나설 예정이라고 합니다. 기존에는 고용위기지역, 특별고용지원업종 등을 지정해 지역과 업종 단위로 기업을 지원했지만, 이를 좀더 효율화하기 위함이라 하네요  '}]}\n",
      "{'messages': [{'role': 'system', 'content': 'You are a helpful Personal assistant. You are to extract the personal experience from each of the posting provided.'}, {'role': 'user', 'content': 'Title: 주간일기 챌린지 8월 1째 주, 이 한 몸 불살랐다.\\n\\nPosting date: 2022-08-06 23:46:37\\n\\npersonal experience: '}, {'role': 'assistant', 'content': '아 썸네일 못 참겠다. 격리 해제 되고 고삐 풀린것 같다. 그래서 좀 쉽지 않다 ..... 무튼 블챌은 해야지 글고 새로운 스티커 들와서 써보겠어요.  격리하는 중 영상 효과를 넣어보았다. 사실 맘에 안드는데 더 건들면 내가 지칠거 같아서 일단 갖고 있는 소스로 여차여차해서 완성 한..몸 띄어쓰기 불편,, 진짜 당일 12시까지 영상 추출이 제대로 안되가지고 1시간 영상 그냥 녹화해서 유튭으로 저장한 담에 틀어버렸다... 그래서 화질도 360 밖에 안되고 초록색 지지직 거려서 솔직히 좀 맘에 안들었다.... 그래도 영상 나온것에 만족을 하며~ 분홍색이 검정색 될때까지 심심해서 원형맘에게 줌을 틀어달라해서 수료피티 거의다 들었다. ㅎ 안에서 바라보는 하늘은 음청 좋은디 더웠다고 한다. 실시간으로 사진 받아가지고 현장감이 느껴지는 순간 물론 부끄러움도 글고 의식하고 싶지 않은데 이젠 자꾸 의식되는 십계조... 이거에 공감할 수 있으면 좀 친하신 분들인걸로 ..ㅎ.ㅎㅎㅎㅎㅎㅎ.ㅎ. 이게 진짜 남이 보는 나인가 금지조항추가되었다 언어 패치 잘못된 조씨... 83 6월 생일이지만 어쩌다보니 미루고 미뤄져서 선물로 밥을 샀는디.. 뭐 내 생일 기대해보겠다고 중랑역 울타리 곱창 가성비 진짜 짱,, 듬직하구먼 ㅎ 나의 풍경샷 84 5개월만에 보는  전주피플 맞이날 미도인에서 마제소바 첨먹고 마제소바 두번째로 먹은 곳인데 요런 느낌의 돼지껍데기 올려진 아부라 소바 같은거시 있어서 도전해봤는데 아주 성공적 매콤해서 오히려 좋았다. 글고 덕분에.. 요런 연극도 보았는디 소소한 레트로 코미디 장르로 재미있었다아아 시간나면 보는것도 추천 와 진짜 한만수님하고 고은실님 맡으신분들 사진으로는 실물이 안담기는데 완전 웹드라마 재질이셨다.. 멋져유 85 새로운걸 배웠다.  86 동아리 면접을 하기위해 아침 9시까지 세종대 갔는데 그나마 가까워서...ㅎ 조금 좋았다. 근데 막판에 기빨려 힘들어 죽는줄,, 글고 여담으로 이번에 모집이 정말 쉽진 않았는데 능력자분들 진짜 많은거 같다. 면접끝내고 밥묵은 담에 전주 피플이 추가로 올라와서 한남동 갔는디 진짜 어항에 있는 것처럼 쉽지 않은 날씨라...뭐 그렇다고요 . 한남동 다운타우너에 있다길래 갔는데 사람 진짜 많다. 8시에도 웨이팅이,, 나는 배가 불르서 I.P.A만..ㅎ 글고 칵테일바를 가기 위해 이태원으로 갔는디... 정말 주말 이태원은 항상 사람이 많다. 이상 여차여차 정신없는 주간일기챌린지 끝~~~ 담주에는 조용히 있어야지 아 낼은 또 면접이지 '}]}\n",
      "{'messages': [{'role': 'system', 'content': 'You are a helpful Personal assistant. You are to extract the personal experience from each of the posting provided.'}, {'role': 'user', 'content': 'Title: Daily 퍼블리  기획에 관심이 있다면 꼭 읽어봐야 할 책 5권  3월 10일\\n\\nPosting date: 2022-03-10 12:48:45\\n\\npersonal experience: '}, {'role': 'assistant', 'content': '카카오, 배민, 라인플러스의 기획자분들이 읽는 책 강미경님, 이준님, 박지현님  오늘은 서비스 기획에 관심이 있으신 분들이 읽으면 좋은 책을 소개해준 글이 있어서 가져와봤습니다 그리고 종류를 보니 기획이 아니더라도 일하는데 있어서 도움이 될 것 같아 참고하시면 좋을 것 같아요 소개 된 책 중에서도 제가 꼭 읽어보고 싶은 책으로 골라보았습니다.ㅎㅎㅎ 1. 인스파이어드 PM직무에 관심이 있다면 한번쯤은 들어봤을 법한 바이블과도 같은 책입니다. 아이디어가 실제 제품이 되기까지 어떤 관점과 방식으로 일해야 하는지 명확한 가이드를 제시해주고 다양한 시각에서 좋은 제품에 대해 생각해볼 수 있다고 합니다. 2. 플랫폼의 생각법 2.0 막연하게 생각하고 있던 플랫폼의 개념을 명확하게 정립해볼 수 있고. 플랫폼이라는 구조가 기존 시장과 차별화를 갖는 방법, 그리고 가치를 만들어서 어떻게 수익구조를 갖는지 설명히 잘되어 있다고 하네요 3. 자기 결정 저명한 철학자이자 작가, 강연가인 페터 비에리가 지은 책으로, 우리가 많은 관심을 쏟고 있는 어떻게 살고, 어떻게 일할 것인가를 고민하기에 앞서, 근본적인 나의 정체성을 찾고, 삶에서 내가 중심이 될 수 있는 내면의 힘을 길러주는 책입니다. 세상에 나를 맞추다가 지쳐 번아웃이 온 분들이 읽으면 도움을 줄 수 있는 책이라고 하네요. 추천하는 글이 많은 만큼 저도 이 책은 꼭 읽어보고 싶다는 생각이 들었어요 4. 프로덕트 리더쉽 꼭 조직의 리더가 아니더라도 기획자나 프로덕트 매니저, 프로덕트 오너에 관심이 있거나 좋은 팀을 만들고 싶으신 분들에게 추천을 하는 책입니다. 기획자와 매니저, 이 두 포지션을 동시에 맡은 케이스를 다루는 책으로 거의 유일하다고 하니 참고하시면 좋을 것 같아요 5. 리더 디퍼런트 이 책은 제가 평소 커리어리에서 즐겨 보는 카카오 플랫폼 기획자이신 이준님께서 추천해주신 책으로 조직을 어떻게 운영하면 좋을지 고민하는 모든 리더분들에게 추천을 하는 책입니다. 일에서 진정한 성과를 얻을 뿐 아니라 구성원 모두가 행복하게 몰입하는 조직을 꿈꾼다면 반드시 도움이 된다고 하니 저도 기회가 되면 꼭 읽어봐야겠다고 생각했어요 '}]}\n",
      "{'messages': [{'role': 'system', 'content': 'You are a helpful Personal assistant. You are to extract the personal experience from each of the posting provided.'}, {'role': 'user', 'content': 'Title: Daily 커리어리   유능한 인재가 이내 떠나는 조직의 공통점 9가지  번아웃을 극복하는 법  1월 24일\\n\\nPosting date: 2022-01-24 12:05:44\\n\\npersonal experience: '}, {'role': 'assistant', 'content': '목차  1. 유능한 인재가 이내 떠나는 조직의 공통점 9가지 Web FE Lead_조은님  2. 번아웃을 극복하는 법 카카오 플랫폼 기획_이준님 1. 유능한 인재가 이내 떠나는 조직의 공통점 9가지   몰입할 수 없는 조직  공부하지 않는 경영진  준비되지 않은 관리자  성장할 공간이 없는 곳  첨단 기술에 뒤쳐지는 곳  잘하고 있나를 정기적으로 체크하지 않는 조직  지나치게 경직된 정책  명확하지 않은 사명  일과 삶의 균형을 깨뜨리는 조직   2. 번아웃을 극복하는 법  번아웃 과도한 업무에서 비롯된 감정적, 신체적, 정신적 고갈상태 조사에 따르면 2020년 지식 노동자의 71가 번아웃을 경험했다고 합니다.  번아웃 징후   일에 대한 두려움이나 냉소  짜증이나 분노  흥미나 동기가 없음  만성 스트레스  성취감 감소  사람들에 대한 회피  무절제한 미루기  새로운 도전에 대한 두려움 번아웃을 유발하는 요인   업무량에 대한 통제권 부족  잘 해낸 일에 대한 인정 부족  업무에 대한 기대가 명확치 않은 것  업무 기대치가 비합리적이고 과도한 것  업무 환경이 고압적인 것  일 때문에 개인 생활을 침해받는 경험  번아웃을 막는 법   휴식 시간도 스케줄로 관리하기 커피를 내리거나 햇볕을 받는 정도가 좋고 전자기기를 멀리하자.   일과 삶의 경계를 정하기 모든 번아웃 요인의 공통점은 외부에서 나에게 밀려드는 무언가라는 점이다.   휴가 내기 해당 기간에 업무가 불가능하다는 의사를 분명히 하고 휴가 중에도 해야 한다면 언제 어떻게 할 것인지 경계를 분명히 할 것   직장에서 관계 형성하기 동료들과의 관계를 형성하고 겪고 있는 어려움을 나누는 것만으로도 회복력을 확보할 수 있다.   일과 목표를 연결하기 자신이 하는 일이 회사의 어떤 목표와 연결이 되어 있는지를 인식하면 애가 왜 이 일을 해야하는지 이해하게 된다.   워라밸 잡기 일과 삶에 대한 투자 균형을 맞추는 것이 중요하다. '}]}\n",
      "{'messages': [{'role': 'system', 'content': 'You are a helpful Personal assistant. You are to extract the personal experience from each of the posting provided.'}, {'role': 'user', 'content': 'Title: Daily 커리어리  데이터 기반 문화를 만들기 위한 10단계  3월15일\\n\\nPosting date: 2022-03-15 09:50:46\\n\\npersonal experience: '}, {'role': 'assistant', 'content': '데이터 기반 문화를 만들기 위한 10단계 마이리얼트립_양승화님 공유 자료  1.문화는 위로부터TopDown 시작되어야 한다.  2.측정을 해야 한다. 꾸준히 해야 한다. 측정할 수 없는 것은 관리할 수 없습니다. 불확실성을 줄이고 장기적으로 예측의 정확도를 높이기 위해서라도 측정지표를 만들고 데이터를 모아야합니다.  3.데이터 사이언티스트는 비즈니스 최전선으로 나와야 한다. 그들이 도메인 지식과 기술 노하우를 융합할 수 있도록 도와주고, 수치에 기반한 대화에 익숙할 수 있도록 도와줘야 합니다.  4.기본적인 데이터 접근은 최대한 쉽게 만들어야 한다. 많은 구성원이 빠르게 회사의 핵심 지표나 전략적으로 중요한 이슈를 읽을 수 있도록 하여 데이터 접근을 용이하게 만들어야 합니다.  5.불확실성을 측정해야 한다. 이를 통해 불확실성의 원인에 대해서도 논의할 수 있는 기회가 생기고, 더 나아가 실험하는 문화가 자연스럽게 생길 수 있습니다.  6.쉬운 것부터 시작해서 성과를 만들어야 한다. 작더라도 확실한 과제에 도전해보아야 합니다.  7. 적절한 시점의 교육이 가장 효과적이다. 필요한 시점 직전에 그에 맞는 교육을 들을 수 있게 해주는 것이 중요합니다.  8.내부 구성원을 위해서 분석기술을 활용해야 한다. 모두가 개발자가 될 필요는 없습니다. 하지만 최소한 업무 자동화RPA등을 통해 기술을 활용할 수 있도록 지원한다면, 기술부서는 조금 더 난이도 있는 업무에 시간을 더 투자할 수 있게 됩니다.  9. 단기적 관점에서는 유연성보다는 일관성이 중요하다.  10.분석적사고로 설명하는 습관을 가져야 한다.  '}]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 데이터 섞기\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# 비율 설정\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(df) * train_ratio)\n",
    "\n",
    "training_df = df.iloc[:train_size]\n",
    "\n",
    "# apply the prepare_example_conversation function to each row of the training_df\n",
    "training_data = training_df.apply(prepare_example_conversation, axis=1).tolist()\n",
    "\n",
    "for example in training_data[:5]:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = df.iloc[train_size:]\n",
    "validation_data = validation_df.apply(prepare_example_conversation, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터들 임시 저장!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsonl(data_list: list, filename: str) -> None:\n",
    "    with open(filename, \"w\") as out:\n",
    "        for ddict in data_list:\n",
    "            jout = json.dumps(ddict) + \"\\n\"\n",
    "            out.write(jout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"finetune_training.jsonl\"\n",
    "write_jsonl(training_data, training_file_name)\n",
    "\n",
    "validation_file_name = \"finetune_validation.jsonl\"\n",
    "write_jsonl(validation_data, validation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 finetune_training.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 파일들과 Validation 파일들을 둘 다 파일로 집어 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-f2fOhksGGXly2ICpCl2YuI6I\n",
      "Validation file ID: file-5s7scrZX5ngxIPOGFDMJ1IuY\n"
     ]
    }
   ],
   "source": [
    "with open(training_file_name, \"rb\") as training_fd:\n",
    "    training_response = openai.files.create(\n",
    "        file=training_fd, purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "training_file_id = training_response.id\n",
    "\n",
    "with open(validation_file_name, \"rb\") as validation_fd:\n",
    "    validation_response = openai.files.create(\n",
    "        file=validation_fd, purpose=\"fine-tune\"\n",
    "    )\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer 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',\n",
    "    # 'Cookie': '__cf_bm=JYS_83E6coMUz_1bKnVVaZ6W3taUOipmkfFEq3N306s-1706230202-1-AUYy9klJoZLMS4R5JRYwl0EqjNucnH3aL5zUEWd3cqXPtXMAuOBdIxij4v+rrfLtLpmWNi6MviOtpxN0H/tEx28=; _cfuvid=AlkgF.dR8z77WrWePIUn925xioNXpPXnjgs3Qb.cAro-1706230202550-0-604800000',\n",
    "}\n",
    "\n",
    "json_data = {\n",
    "    'training_file': 'file-f2fOhksGGXly2ICpCl2YuI6I',\n",
    "    'validation_file': 'file-5s7scrZX5ngxIPOGFDMJ1IuY',\n",
    "    'model': 'ft:gpt-3.5-turbo-0613:sesac::8l6SEuCZ',\n",
    "    'hyperparameters': {\n",
    "        'n_epochs': 5,\n",
    "    },\n",
    "}\n",
    "\n",
    "response = requests.post('https://api.openai.com/v1/fine_tuning/jobs', headers=headers, json=json_data)\n",
    "\n",
    "# Note: json_data will not be serialized by requests\n",
    "# exactly as it was in the original request.\n",
    "#data = '{\\n    \"training_file\": \"file-f2fOhksGGXly2ICpCl2YuI6I\",\\n    \"validation_file\":\"file-5s7scrZX5ngxIPOGFDMJ1IuY\",\\n    \"model\": \"gpt-3.5-turbo\",\\n    \"hyperparameters\": {\\n      \"n_epochs\": 10\\n    }\\n  }'\n",
    "#response = requests.post('https://api.openai.com/v1/fine_tuning/jobs', cookies=cookies, headers=headers, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\n  \"object\": \"fine_tuning.job\",\\n  \"id\": \"ftjob-zAMH2ZFaWkQjDqhgszcqmwzC\",\\n  \"model\": \"ft:gpt-3.5-turbo-0613:sesac::8l6SEuCZ\",\\n  \"created_at\": 1706252968,\\n  \"finished_at\": null,\\n  \"fine_tuned_model\": null,\\n  \"organization_id\": \"org-8UeoETlkDlwBhEyyCCaEMxdF\",\\n  \"result_files\": [],\\n  \"status\": \"validating_files\",\\n  \"validation_file\": \"file-5s7scrZX5ngxIPOGFDMJ1IuY\",\\n  \"training_file\": \"file-f2fOhksGGXly2ICpCl2YuI6I\",\\n  \"hyperparameters\": {\\n    \"n_epochs\": 5,\\n    \"batch_size\": \"auto\",\\n    \"learning_rate_multiplier\": \"auto\"\\n  },\\n  \"trained_tokens\": null,\\n  \"error\": null\\n}'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1468476944.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    hyperparameters: {\"n_epochs\": 10}\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "response = openai.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=\"blog posting\",\n",
    "    hyperparameters: {\"n_epochs\": 10}\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-zAMH2ZFaWkQjDqhgszcqmwzC\n",
      "Validating training file: file-f2fOhksGGXly2ICpCl2YuI6I and validation file: file-5s7scrZX5ngxIPOGFDMJ1IuY\n",
      "File file-f2fOhksGGXly2ICpCl2YuI6I contains examples greater than the supported context size for model `gpt-3.5-turbo-0613` (4096 tokens)\n",
      "Files validated, moving job to queued state\n",
      "Fine-tuning job started\n"
     ]
    }
   ],
   "source": [
    "response = openai.fine_tuning.jobs.list_events('ftjob-zAMH2ZFaWkQjDqhgszcqmwzC')\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0613:sesac::8lBIAPD3\n"
     ]
    }
   ],
   "source": [
    "response = openai.fine_tuning.jobs.retrieve('ftjob-zAMH2ZFaWkQjDqhgszcqmwzC')\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "\n",
    "if fine_tuned_model_id is None: \n",
    "    raise RuntimeError(\"Fine-tuned model ID not found. Your job has likely not been completed yet.\")\n",
    "\n",
    "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_id ='ft:gpt-3.5-turbo-0613:sesac::8l6SEuCZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft:gpt-3.5-turbo-0613:sesac::8l6SEuCZ (10번)\n",
    "# ft:gpt-3.5-turbo-0613:sesac::8lBIAPD3 (파인 튜닝 또)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "sample = {\n",
    "    'title': ['설날에 국밥을 먹었다.'], \n",
    "    'date': [datetime.now()]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful Personal assistant. You are to extract the '\n",
      "             'personal experience from each of the posting provided.',\n",
      "  'role': 'system'},\n",
      " {'content': \"Title: ['설날에 국밥을 먹었다.']\\n\"\n",
      "             '\\n'\n",
      "             'Posting date: [datetime.datetime(2024, 1, 26, 17, 11, 37, '\n",
      "             '535647)]\\n'\n",
      "             '\\n'\n",
      "             'personal experience: ',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "user_message = create_user_message(sample)\n",
    "test_messages.append({\"role\": \"user\", \"content\": create_user_message(sample)})\n",
    "\n",
    "pprint(test_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 오늘은 설날.... 쉬는날지도 아닌 쉬는 날인 대구만의 대단한 경제력 측정법인지 모르겠지만 대부분의 회사가 오늘은 휴무인 것 같다. 나는 어제부터 과제를 좀 끝내야 하기도 하고 쉬는 날이라 그런지 모르겠지만 늦게 일어나고 뭔가 모르게 하루종일 멍하니 있던 것 같다.  그래서 오늘은 좀 일찍이라도 나와서 블챌 목표량을 좀 채워보는 걸로  글고 블챌 후에는 코스트코에 간다~. 사실 코스트코에 가는 이유는 김치를 사러 가는 것 밖에는 없는 것 같다. 당근 김치가 무지 맛있기도 하다. 그리고 코스트코에 가면 늘 사먹었던 푸드도 좀 사먹는 편인데 이번 설 특집으로 인해 일반 푸드 가격이 얼마전보다 무지 비쌌다. 원래 3300원정도 올라서 13000원인 것을 보았는데 나는 평소 별로 먹을 생각도 없어서 ㅎㅎ 소소한 만족을 한 것 같다.  그리고 이날의 점심은 설특집으로 인해 집을 대신하는 용산역 근처 시청소재 한식집에서 국밥을 먹었다. 사실 이날 용산 한시간을 기준으로 정말 종로3가와 가까워서 종로3가로 가는 것도 좀 있었는데 난 이날 용산 간거 가지고 이제 용산에 가는 건 없을 것 같다.  왜냐하면.... 용산역은 정말 복잡하다. 그리고 나는 이제 이 근처에 위치한 시청소재 음식점과 카페를 조져버렸다.  이번에 국밥을 먹은 곳도 사람 많은 곳은 아니였지만 괜찮은 맛집을 추천 받아서 간거 같다. 글고 새로운 맛집을 찾는다고 튕기는 경우가 거의 대부분인 나는 이제 맛집 사찰이라는 개념으로 다시 한번 찾아볼 만한 곳을 가야겠다.  아래는 오늘의 국밥 사진이다.  설날 메뉴로 밥 대신에 떡국에 들어간 손납작이 정말 맛있었다. 양도 많았다. 저기에 들어간 돼지고기도 쫄깃쫄깃 ㅎ 돼지껍데기는 좀 얇긴 했지만 크기는 어지간한 것 같다. 그래도 김가온씨 집 껍데기 못하지 않게 김이 다 붙어 있어서 좋았다. 글고 오른쪽에 있는건 무침인데 솔직히 그릇에 밥이랑 같이 나와도 배불러 죽을 것 같은 느낌적인 느낌이다.  그래서 새로운 떡국 맛집을 가보고 싶은 생각이 들었다.  머리는 공기계로 짧게 자르고 옆넓이는 3번이나 돌려서 2.5cm로 만들어 버렸다.  이번에는 다듬은 과정에서 카메라가 멈춰버렸다. 다듬을 때마다 카메라 꺼지는 거 싫어지 ㅎㅎㅎ 언능 좋은 카메라 사와야지 허허 이제 이렇게 남겨진 털이 좀 많은 것 같기도 하다. 털 다듬는 과정에서 빠지는 것도 아쉽구만 ㅎㅎㅎㅎ 털 좀 잘라서 업스타일 했는데 뭔가 새로운 느낌  새해 복 많이 받으세요. 이제 힘내보자~ \n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=fine_tuned_model_id, messages=test_messages, temperature=0.6, max_tokens=4000, seed=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
